{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROBOLOAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Review the first data set: Accepted loans\n",
    "original_data_1 = pd.read_csv('accepted_2007_to_2018_100T.csv', low_memory=False)\n",
    "original_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the second data set: Rejected loans\n",
    "\n",
    "original_data_2 = pd.read_csv('rejected_2007_to_2018_100T.csv', low_memory=False, encoding=\"ISO-8859-1\")\n",
    "original_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Attributes' Explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove all columns and rows with NaN values and choose some needed attributes\n",
    "\n",
    "data_accepted = original_data_1[['loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'emp_length', 'home_ownership', \n",
    "                     'annual_inc', 'verification_status', 'issue_d', 'loan_status', 'purpose', 'open_acc', 'dti', 'total_acc', \n",
    "                     'fico_range_low', 'fico_range_high', 'addr_state', 'policy_code']]\n",
    "data_accepted = data_accepted.dropna()\n",
    "\n",
    "data_accepted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of attributes of accepted loans dataset \n",
    "\n",
    "data_accepted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for converting ordinal values to numeric values\n",
    "def ordinal_feature(data, columns):\n",
    "    \"\"\" \n",
    "        - Takes only ordinal variables (in quantative or alphabetic order) to convert it into integer\n",
    "        - Important: Takes two arguments\n",
    "        - param data: Dataset\n",
    "        - param columns: features, which have to be converted to ordinals\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        converted_order = []\n",
    "        count = 0\n",
    "        values = list(data[column].unique())\n",
    "        values = sorted(values)\n",
    "        for value in values:\n",
    "            value = str(value)\n",
    "            if value.startswith(\"<\"):\n",
    "                converted_order.insert(0, value)\n",
    "            elif \"+\" in value:\n",
    "                converted_order.insert(count + 1, value)\n",
    "            else:\n",
    "                converted_order.insert(count, value)\n",
    "                count += 1\n",
    "        data[column] = data[column].apply(lambda x: converted_order.index(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting ordinal values to numeric values\n",
    "ordinals = [\"emp_length\"]\n",
    "ordinal_feature(data_accepted, ordinals)\n",
    "\n",
    "data_accepted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling statistics of accepted loans\n",
    "data_accepted.describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the needed features from original rejected data set and clear from NaN values\n",
    "data_rejected = original_data_2[['Amount Requested', 'Application Date', 'Loan Title', 'Risk_Score', 'Debt-To-Income Ratio', \n",
    "                                 'Employment Length','State', 'Policy Code;;']]\n",
    "data_rejected = data_rejected.dropna()\n",
    "\n",
    "# remove the persentage and unneeded signs from the values\n",
    "data_rejected['Debt-To-Income Ratio'] =  data_rejected['Debt-To-Income Ratio'].str.strip('%').astype('float')\n",
    "data_rejected['Policy Code;;'] = data_rejected['Policy Code;;'].str.strip(';;').astype('float')\n",
    "\n",
    "# convert the values to numerical type\n",
    "data_rejected['Amount Requested'] = data_rejected['Amount Requested'].astype('float')\n",
    "data_rejected['Risk_Score'] = data_rejected['Risk_Score'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ordinal features to numeric values in the rejected loan data set\n",
    "\n",
    "ordinals = [\"Employment Length\"]\n",
    "ordinal_feature(data_rejected, ordinals)\n",
    "\n",
    "data_rejected.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute explanations of rejected loans? \n",
    "\n",
    "data_rejected.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rejected.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Merge both data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generelize the common features of both data sets \n",
    "common_features = {\"loan_amnt\":\"Loan Amount\", \"Amount Requested\":\"Loan Amount\", \"issue_d\": \"Application Date\", \n",
    "                   \"purpose\": \"Loan Title\", \"dti\": \"Debt-To-Income Ratio\", \"emp_length\": \"Employment Length\",\n",
    "                   \"addr_state\": \"State\", \"Policy Code;;\": \"Policy Code\", \"policy_code\": \"Policy Code\"}\n",
    "\n",
    "# Attribute Risk score is in different form. In accepted data it is splited in low and high fico range. We take the mean of them\n",
    "data_accepted[\"Risk_Score\"] = data_accepted[['fico_range_low', 'fico_range_high']].mean(axis=1)\n",
    "data_accepted = data_accepted.drop(['fico_range_low', 'fico_range_high'], axis=1)\n",
    "\n",
    "data_accepted_m = data_accepted.rename(columns=common_features)\n",
    "data_rejected_m = data_rejected.rename(columns=common_features)\n",
    "\n",
    "for i in data_accepted_m.columns:\n",
    "    if i not in data_rejected_m.columns:\n",
    "        data_accepted_m = data_accepted_m.drop([i], axis=1)\n",
    "        \n",
    "merged_data = pd.concat([data_accepted_m, data_rejected_m], ignore_index=True, sort=True)\n",
    "merged_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style, font and formats for plotting discriptive statistics\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "mpl.rcParams['font.size'] = '14'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loan and interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 16))\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Loan Amount\n",
    "plt.subplot(4, 1, 1, facecolor='#eeefff')\n",
    "sns.histplot(x='loan_amnt', data=data_accepted, color='#21AFC3', kde=True)\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Loan Amount', fontsize=16)\n",
    "plt.tight_layout(pad=2)\n",
    "\n",
    "# Interest Rate\n",
    "plt.subplot(4, 1, 2, facecolor='#eeefff')\n",
    "sns.lineplot(data=sorted(data_accepted['int_rate'].unique()), color='#EA2B6B')\n",
    "plt.plot(data_accepted['int_rate'].unique(), 'bo')\n",
    "plt.xlabel(\"Unique values\")\n",
    "plt.ylabel('Rate')\n",
    "plt.title('Interest rate', fontsize=16)\n",
    "plt.ylim(0, data_accepted['int_rate'].max() + 5)\n",
    "plt.xlim(0, len(data_accepted['int_rate'].unique()))\n",
    "plt.tight_layout(pad=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distributions of other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 20))\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Purpose of taking loan \n",
    "plt.subplot(4, 2, 1, facecolor = '#eeefff')\n",
    "data_accepted['purpose'].value_counts().plot(kind='bar', color='#03B9FD')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Purpose', fontsize=16)\n",
    "\n",
    "# Duration of loan\n",
    "plt.subplot(4, 2, 2, facecolor='#eeefff')\n",
    "data_accepted['term'].value_counts().plot(kind='bar', color='#EA2B6B')\n",
    "plt.title('Duration of loan', fontsize=16)\n",
    "\n",
    "# Information about home ownership of applicants\n",
    "plt.subplot(4, 2, 3, facecolor = '#eeefff')\n",
    "data_accepted['home_ownership'].value_counts().plot(kind='bar', color='#FCBF8C')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Home ownership', fontsize=16)\n",
    "plt.tight_layout(pad=2)\n",
    "\n",
    "# Information about grades frequency\n",
    "plt.subplot(4, 2, 4, facecolor='#eeefff')\n",
    "sns.countplot(x='grade', data=data_accepted, palette=\"rocket\")\n",
    "plt.xlabel(None)\n",
    "plt.title('Grades', fontsize=16)\n",
    "\n",
    "# Verification_status\n",
    "plt.subplot(4, 2, 5, facecolor='#eeefff')\n",
    "data_accepted['verification_status'].value_counts().plot(kind='bar', color='#21AFC3')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel(None)\n",
    "plt.title('Varification Status', fontsize=16)\n",
    "\n",
    "# Loan status\n",
    "plt.subplot(4, 2, 6, facecolor='#eeefff')\n",
    "data_accepted['loan_status'].value_counts().plot(kind='bar', color='#FDA603')\n",
    "plt.xlabel(None)\n",
    "plt.title('Loan Status', fontsize=16)\n",
    "\n",
    "# Employment lenght\n",
    "plt.subplot(4, 2, 7, facecolor = '#eeefff')\n",
    "sns.countplot(x='emp_length', data=data_accepted, palette=\"GnBu_d\")\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Employment Length', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Contingency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan status vs grade\n",
    "\n",
    "pd.crosstab(data_accepted['loan_status'], data_accepted['grade']).style.background_gradient(cmap = \"Purples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan status vs home ownership\n",
    "\n",
    "pd.crosstab(data_accepted['loan_status'], data_accepted['home_ownership']).style.background_gradient(cmap = \"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan status and employment lenght\n",
    "\n",
    "pd.crosstab(data_accepted['loan_status'], data_accepted['emp_length']).style.background_gradient(cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loan status vs loan amount\n",
    "\n",
    "data_accepted.groupby(by='loan_status')['loan_amnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Plot the distribution of loan amounts with laon statuses\n",
    "sns.histplot(data=data_accepted, x=\"loan_amnt\", hue=\"loan_status\", stat='count', multiple=\"stack\", palette=\"Set1\", bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade vs employment length\n",
    "\n",
    "pd.crosstab(data_accepted['grade'], data_accepted['emp_length']).style.background_gradient(cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade vs home ownership\n",
    "\n",
    "pd.crosstab(data_accepted['grade'], data_accepted['home_ownership']).style.background_gradient(cmap = \"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# loan amount and homeownership\n",
    "sns.histplot(data=data_accepted, x=\"loan_amnt\", hue=\"home_ownership\", multiple=\"stack\", palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of the loans' amount\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Information about grades frequency \n",
    "plt.subplot(2, 2, 1, facecolor = '#eeefff')\n",
    "sns.violinplot(data=data_accepted, x=\"home_ownership\", y=\"loan_amnt\", split=True, palette='coolwarm')\n",
    "plt.ylabel(\"Loan Amount\")\n",
    "plt.xlabel(None)\n",
    "plt.title(\"Homer Ownership with Loan Amount Distribuition\", fontsize=16)\n",
    "\n",
    "plt.subplot(2, 2, 2, facecolor = '#eeefff')\n",
    "sns.violinplot(data=data_accepted, x=\"home_ownership\", y=\"int_rate\", split=True, palette='Spectral')\n",
    "plt.ylabel(\"Interest Rate\")\n",
    "plt.xlabel(None)\n",
    "plt.title(\"Homer Ownership with Interest Rate\", fontsize=16)\n",
    "\n",
    "plt.subplot(2, 2, 3, facecolor = '#eeefff')\n",
    "sns.violinplot(data=data_accepted, x=\"home_ownership\", y=\"int_rate\", hue=\"term\", split=True, palette='coolwarm')\n",
    "plt.ylabel(\"Interest Rate\")\n",
    "plt.xlabel(None)\n",
    "plt.title(\"Homer Ownership with Interest Rate\", fontsize=16)\n",
    "\n",
    "plt.subplot(2, 2, 4, facecolor = '#eeefff')\n",
    "sns.boxplot(data=data_accepted, x=\"grade\", y=\"int_rate\", palette='pastel')\n",
    "plt.ylabel(\"Interest Rate\")\n",
    "plt.xlabel(None)\n",
    "plt.title(\"Grades with Interest Rate\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 15))\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "# Homeownership and duration of loan\n",
    "plt.subplot(3, 2, 1)\n",
    "sns.countplot(x='term', data=data_accepted, hue='home_ownership')\n",
    "plt.legend(loc=1)\n",
    "plt.title(\"Homer Ownership with Duration\", fontsize=16)\n",
    "\n",
    "# Homeownership and duration of loan\n",
    "plt.subplot(3, 2, 2)\n",
    "sns.countplot(x='term', data=data_accepted, hue='verification_status')\n",
    "plt.legend(loc=1)\n",
    "plt.tight_layout(pad=2)\n",
    "\n",
    "# Homeownership, interest rate and varification status\n",
    "plt.subplot(3, 2, 3, facecolor = '#eeefff')\n",
    "sns.boxplot(data=data_accepted, x=\"home_ownership\", y=\"int_rate\", hue=\"verification_status\", palette='pastel')\n",
    "plt.ylabel(\"Interest Rate\")\n",
    "plt.xlabel(None)\n",
    "plt.legend(loc=1)\n",
    "plt.title(\"Homer Ownership with Interest Rate\", fontsize=16)\n",
    "\n",
    "# Homeownership, interest rate and varification status\n",
    "plt.subplot(3, 2, 4, facecolor = '#eeefff')\n",
    "sns.boxplot(data=data_accepted, x=\"home_ownership\", y=\"int_rate\", hue=\"term\", palette='pastel')\n",
    "plt.ylabel(\"Interest Rate\")\n",
    "plt.xlabel(None)\n",
    "plt.legend(loc=1)\n",
    "plt.title(\"Homer Ownership with Interest Rate\", fontsize=16)\n",
    "\n",
    "# Grade and duration of loan\n",
    "plt.subplot(3, 2, 5)\n",
    "sns.countplot(x='term', data=data_accepted, hue='grade')\n",
    "plt.legend(loc=1)\n",
    "plt.title(\"Homer Ownership with Duration\", fontsize=16)\n",
    "\n",
    "# Homeownership, interest rate and varification status\n",
    "plt.subplot(3, 2, 6, facecolor = '#eeefff')\n",
    "sns.boxplot(data=data_accepted, x=\"annual_inc\", hue=\"grade\", palette='pastel')\n",
    "plt.legend(loc=1)\n",
    "plt.title(\"\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting correlation matrices\n",
    "def correlation_matrix(data):\n",
    "    \"\"\" \n",
    "        Takes as an input a data set.\n",
    "        Plots correlation matrix\n",
    "    \"\"\"\n",
    "    labels_cr = data.columns\n",
    "    corr_table = np.array(data.round(3))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 12))\n",
    "    ax.imshow(corr_table, cmap='twilight_shifted')\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(labels_cr)))\n",
    "    ax.set_yticks(np.arange(len(labels_cr)))\n",
    "    ax.set_xticklabels(labels_cr)\n",
    "    ax.set_yticklabels(labels_cr)\n",
    "    ax.grid(False)\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=14)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=14)\n",
    "\n",
    "    for i in range(len(labels_cr)):\n",
    "        for j in range(len(labels_cr)):\n",
    "            text = ax.text(j, i, corr_table[i, j], ha='center', va='center', color='w', fontsize=14)\n",
    "        \n",
    "    ax.set_title(\"Correlation of features\".upper(), fontsize=14)\n",
    "    fig.tight_layout()  \n",
    "\n",
    "    fig.colorbar(ax.imshow(corr_table, cmap='twilight_shifted'), orientation='horizontal', label='Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of features of the accepted loan data set\n",
    "data_accepted.drop([\"policy_code\"], axis=1).corr().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix plot of accepted loan data set\n",
    "correlation_matrix(data_accepted.drop([\"policy_code\"], axis=1).corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rejected.drop([\"Policy Code;;\"], axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(data_rejected.drop([\"Policy Code;;\"], axis=1).corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing Machine learning models \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data preparation for ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration to numerical value\n",
    "data_accepted['term'] = data_accepted['term'].str.strip('months').astype('int')\n",
    "\n",
    "# drop issued date\n",
    "data_accepted = data_accepted.drop(['issue_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert grades to numerical order using function ordinal feature\n",
    "ordinals = [\"grade\"]\n",
    "ordinal_feature(data_accepted, ordinals)\n",
    "\n",
    "data_accepted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_accepted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for converting categorical variables to dummy values\n",
    "def onehot_encode(data, columns):\n",
    "    data = data.copy()\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(data[column], prefix=column)\n",
    "        data = pd.concat([data, dummies], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting values to dummy values\n",
    "onehot_encode(data_accepted, columns=['home_ownership', 'verification_status', 'purpose', 'addr_state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Unsupervised Machine Learning model - K-means\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessery libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the values to dummy values\n",
    "X = onehot_encode(data_accepted, columns=[['home_ownership', 'verification_status', 'purpose', 'addr_state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating the target variable from the predictor variables \n",
    "target_column = data_accepted['loan_status'] \n",
    "X = X.drop(['loan_status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Assigning numerical values to labels and storing in another column\n",
    "target_column = labelencoder.fit_transform(target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model K-means from scikit library\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "KModel = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted categories\n",
    "KModel.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters' centers\n",
    "KModel.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparason of predicted clusters with predefined given categories (target column)\n",
    "pd.crosstab(target_column, KModel.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(target_column, KModel.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 K-Nearest Neighbors (Supervised model)\n",
    "\n",
    "1. Find K records that have similar features (i.e., similar predictor values).\n",
    "2. For classification, find out what the majority class is among those similar records and assign that class to the new record.\n",
    "3. For prediction (also called KNN regression), find the average among those similar records, and predict that average for the new record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.drop(['Application Date', 'Loan Title', \"State\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  K-Nearest Neighbors we take concated dataset just to show how it works. The outcome is the feature risk score. \n",
    "merged_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# define the features for prediction\n",
    "predictors = [\"Debt-To-Income Ratio\", \"Employment Length\", \"Loan Amount\", \"Risk_Score\"]\n",
    "outcome = \"Policy Code\"\n",
    "\n",
    "# define the prediction variables and outcome variabales\n",
    "X = merged_data.loc[:, predictors].values\n",
    "y = merged_data.loc[:, outcome].values\n",
    "\n",
    "# Split data into training data and testing data (30% of data).  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "# standardize values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# fit the model with certain number of neighbors (Ks)\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction of test part (30% data for test without outcomes)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the quality of the model using confusion matrix.\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the quality of the model\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- https://learning.oreilly.com/library/view/machine-learning-with/9780134845708/ch03.xhtml#ch03\n",
    "- https://learning.oreilly.com/library/view/practical-statistics-for/9781492072935/ch06.html#StatisticalML\n",
    "- https://learning.oreilly.com/library/view/machine-learning-for/9781789136364/ch02s02.html\n",
    "- https://learning.oreilly.com/library/view/python-for-finance/9781492024323/ch13.html\n",
    "- https://pandas.pydata.org\n",
    "- https://matplotlib.org\n",
    "- https://www.kaggle.com/wordsforthewise\n",
    "- https://scikit-learn.org\n",
    "- https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Необработанный формат ячейки",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
